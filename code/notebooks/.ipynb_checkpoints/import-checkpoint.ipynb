{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from dask.diagnostics import ProgressBar\n",
    "progress = ProgressBar().register()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMG_DIR = '../../analysis'\n",
    "DPI=120"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data using Dask (loads lazily)\n",
    "* https://www.youtube.com/watch?v=RA_2qdipVng&t=1s\n",
    "* http://matthewrocklin.com/slides/scipy-2017.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 78.1 ms, sys: 250 ms, total: 328 ms\n",
      "Wall time: 359 ms\n"
     ]
    }
   ],
   "source": [
    "# data_types = {'CRSElapsedTime': int, 'CRSDepTime': int, 'Year': int, 'Month': int, 'DayOfWeek': int, 'DayofMonth': int}\n",
    "data_types = {'CRSDepTime': int, 'Year': int, 'Month': int, 'DayOfWeek': int, 'DayofMonth': int}\n",
    "\n",
    "\n",
    "# http://dask.pydata.org/en/latest/dataframe-overview.html\n",
    "# %time df = dd.read_csv('../../data/raw/*.csv', encoding='iso-8859-1', dtype=data_types, assume_missing=True, blocksize=1024 * 1024)\n",
    "# %time df = dd.read_csv('../../data/raw/*.csv', encoding='iso-8859-1', dtype=data_types, assume_missing=True)\n",
    "%time df = dd.read_csv('../../data/raw/2002.csv', encoding='iso-8859-1', dtype=data_types, assume_missing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %time df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.6 ms, sys: 15.6 ms, total: 31.2 ms\n",
      "Wall time: 27.2 ms\n"
     ]
    }
   ],
   "source": [
    "%time df = df.fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes a while\n",
    "# %time df.count().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Takes a while, but should be doable\n",
    "# %time unique_origins = df['Origin'].unique().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# once you compute you get a real pandas series\n",
    "# type(unique_origins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# unique_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2400 is not a valid time\n",
    "df['CRSDepTime'] = df.apply(lambda row: 2359 if row['CRSDepTime'] == 2400 else row['CRSDepTime'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.apply?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[########################################] | 100% Completed | 23.1s\n"
     ]
    }
   ],
   "source": [
    "head = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_timestamp (row):\n",
    "    return pd.Timestamp('%s-%s-%s;%04d'%(row['Year'], row['Month'], row['DayofMonth'], row['CRSDepTime']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# type(head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a sample for dask to figure out the data types\n",
    "transformation_sample = head.apply(create_timestamp, axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(transformation_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2002-01-13 22:35:00')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformation_sample[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# meta_information = {'@timestamp': pd.Timestamp}\n",
    "meta_information = transformation_sample\n",
    "\n",
    "df['@timestamp'] = df.apply(lambda row: pd.Timestamp('%s-%s-%s;%04d'%(row['Year'], row['Month'], row['DayofMonth'], row['CRSDepTime'])),\n",
    "                            axis='columns',\n",
    "                           meta=meta_information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyelasticsearch import ElasticSearch, bulk_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ES_HOST = 'http://localhost:9200/'\n",
    "INDEX_NAME = \"expo2009\"\n",
    "DOC_TYPE = \"flight\"\n",
    "es = ElasticSearch(ES_HOST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://pyelasticsearch.readthedocs.io/en/latest/api/#pyelasticsearch.ElasticSearch.bulk\n",
    "def documents(records):\n",
    "    for flight in records:\n",
    "        yield es.index_op(flight)\n",
    "        \n",
    "def chunk_import(records):        \n",
    "    # bulk_chunks() breaks your documents into smaller requests for speed:\n",
    "    for chunk in bulk_chunks(documents(records=records),\n",
    "                             docs_per_chunk=50000,\n",
    "                             bytes_per_chunk=10000000):\n",
    "        # We specify a default index and doc type here so we don't\n",
    "        # have to repeat them in every operation:\n",
    "        es.bulk(chunk, doc_type=DOC_TYPE, index=INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12140825"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# should be 2 initially or 0, depending on if kibana hasrun already\n",
    "es.count('*')['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.npartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "begin_partition = 0\n",
    "end_partition = df.npartitions\n",
    "\n",
    "# begin_partition = 23\n",
    "# end_partition = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing partition 0\n",
      "[########################################] | 100% Completed |  2min 39.9s\n",
      "Importing into ES: 637003\n",
      "Datasets in ES: 12285083\n",
      "Time loading: 358.014\n",
      "[                                        ] | 0% Completed |  0.0sImporting partition 1\n",
      "[########################################] | 100% Completed |  2min 42.5s\n",
      "Importing into ES: 636510\n",
      "Datasets in ES: 12921153\n",
      "Time loading: 363.954\n",
      "[                                        ] | 0% Completed |  0.0s\n",
      "[########################################] | 100% Completed |  2min 35.7s\n",
      "Importing into ES: 640252\n",
      "Datasets in ES: 13559346\n",
      "[                                        ] | 0% Completed |  0.0s\n",
      "Importing partition 3\n",
      "[########################################] | 100% Completed |  2min 30.4s\n",
      "Importing into ES: 636826\n",
      "Datasets in ES: 14200553\n",
      "[                                        ] | 0% Completed |  0.0s\n",
      "Importing partition 4\n",
      "[########################################] | 100% Completed |  2min 38.7s\n",
      "Importing into ES: 639237\n",
      "Datasets in ES: 14839229\n",
      "Time loading: 368.125\n",
      "[                                        ] | 0% Completed |  0.0s\n",
      "[########################################] | 100% Completed |  2min 36.3s\n",
      "Importing into ES: 636553\n",
      "Datasets in ES: 15474202\n",
      "[                                        ] | 0% Completed |  0.0s\n",
      "Importing partition 6\n",
      "[########################################] | 100% Completed |  2min 34.7s\n",
      "Importing into ES: 631200\n",
      "Datasets in ES: 16106026\n",
      "[                                        ] | 0% Completed |  0.0s\n",
      "Importing partition 7\n",
      "[########################################] | 100% Completed |  2min 55.5s\n",
      "Importing into ES: 632999\n",
      "Datasets in ES: 16738214\n",
      "Time loading: 362.899\n",
      "[                                        ] | 0% Completed |  0.0sImporting partition 8\n",
      "[########################################] | 100% Completed | 50.0s\n",
      "Importing into ES: 180779\n",
      "Datasets in ES: 16917753\n",
      "Time loading: 106.667\n"
     ]
    }
   ],
   "source": [
    "for partition_nr in range(df.npartitions):\n",
    "    if partition_nr >= end_partition:\n",
    "        break\n",
    "    if partition_nr < begin_partition:\n",
    "        continue\n",
    "    t0 = time()\n",
    "    print (\"Importing partition %d\"%(partition_nr))\n",
    "    partition = df.get_partition(partition_nr)\n",
    "    records = partition.compute().to_dict(orient='records')\n",
    "    print (\"Importing into ES: %d\"%(len(records)))    \n",
    "    chunk_import(records)\n",
    "    cnt = es.count('*')['count']\n",
    "    print (\"Datasets in ES: %d\"%(cnt))\n",
    "    print(\"Time loading: %s\"%(round(time() - t0, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
